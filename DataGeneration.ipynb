{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Independent Predictor Simulations'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Independent Predictor Simulations\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a design matrix X with n = 100 iid examples and p = 9 predictors from a MVN_p(0,I) distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 100\n",
    "p1 = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeromean = np.zeros(p1)\n",
    "covI = np.diag(np.ones(p1))\n",
    "\n",
    "# Use seed 42 to generate X\n",
    "X = stats.multivariate_normal.rvs(mean=zeromean,cov=covI,size=n1,random_state=42)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate the response y.\n",
    "# Assume y = XB with true Beta = [0.8,1.5,0,...,0]\n",
    "# Use seed 100 to generate the regression errors\n",
    "\n",
    "true_beta = np.reshape(np.concatenate(([0.8,1.5],np.zeros(p1-2))),(-1,1))\n",
    "random_errors = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n1),cov=np.diag(np.ones(n1)),random_state=100), (-1,1))\n",
    "y = np.matmul(X,true_beta) + random_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to save X and y\n",
    "filename = \"Data/training_data100x9.pickle\" # Aim to save the data in this file\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename)) # Create the Data Directory...\n",
    "except FileExistsError:\n",
    "    pass # Unless it already exists, in which case, do nothing\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([X,y],file) # Dump the training data into the aforementioned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 different datasets X with 100 samples from a MVN(0,I) dataset with p=9 parameters\n",
    "# Use random seeds 1,2,...,50\n",
    "n2 = 100\n",
    "p2 = 9\n",
    "num_datasets = 50\n",
    "\n",
    "datasets = np.zeros((num_datasets,n2,p2))\n",
    "for batchidx in range(num_datasets):\n",
    "    datasets[batchidx] = stats.multivariate_normal.rvs(mean=np.zeros(p2),cov=np.diag(np.ones(p2)),random_state = batchidx+1,size=n2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset, generate random errors from a MVN(0,1) distribution of dimension n2\n",
    "# Use random seeds 1001,...,1050\n",
    "random_errors = np.zeros((num_datasets,n2,1))\n",
    "for batchidx in range(num_datasets):\n",
    "    random_errors[batchidx] = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n2),cov=np.diag(np.ones(n2)),random_state=1001+batchidx),(n2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 100, 1) (50, 100, 9)\n"
     ]
    }
   ],
   "source": [
    "# Define true parameter beta = [0.8,1.5,0,...,0]\n",
    "trueBeta = np.reshape(np.concatenate(([0.8,1.5],np.zeros(p2-2)),axis=0),(-1,1))\n",
    "response = np.matmul(datasets,trueBeta) + random_errors\n",
    "print(response.shape, datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now need to save the datasets and responses in a numpy file\n",
    "filename = \"Data/GeneratedSets50x100x9.pickle\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([datasets,response],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Independent predictors with less examples, but n > p'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Independent predictors with less examples, but n > p\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a design matrix X with n = 15 iid examples and p = 9 predictors from a MVN_p(0,I) distribution\n",
    "n3 = 15\n",
    "p3 = 9\n",
    "\n",
    "zeromean = np.zeros(p3)\n",
    "covI = np.diag(np.ones(p3))\n",
    "\n",
    "# Use seed 43 to generate X\n",
    "X = stats.multivariate_normal.rvs(mean=zeromean,cov=covI,size=n3,random_state=43)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate the response y.\n",
    "# Assume y = XB with true Beta = [0.8,1.5,0,...,0]\n",
    "# Use seed 101 to generate the regression errors\n",
    "\n",
    "true_beta = np.reshape(np.concatenate(([0.8,1.5],np.zeros(p3-2))),(-1,1))\n",
    "random_errors = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n3),cov=np.diag(np.ones(n3)),random_state=101), (-1,1))\n",
    "y = np.matmul(X,true_beta) + random_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to save X and y\n",
    "filename = \"Data/training_data15x9.pickle\" # Aim to save the data in this file\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename)) # Create the Data Directory...\n",
    "except FileExistsError:\n",
    "    pass # Unless it already exists, in which case, do nothing\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([X,y],file) # Dump the training data into the aforementioned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 9) (15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 25 different datasets X with 15 examples from a MVN(0,I) dataset with p=9 parameters\n",
    "# Use random seeds 101,102,...,125\n",
    "n4 = 15\n",
    "p4 = 9\n",
    "num_datasets = 25\n",
    "\n",
    "datasets = np.zeros((num_datasets,n4,p4))\n",
    "for batchidx in range(num_datasets):\n",
    "    datasets[batchidx] = stats.multivariate_normal.rvs(mean=np.zeros(p4),cov=np.diag(np.ones(p4)),random_state = batchidx+101,size=n4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset, generate random errors from a MVN(0,1) distribution of dimension n2\n",
    "# Use random seeds 2001,...,2025\n",
    "random_errors = np.zeros((num_datasets,n4,1))\n",
    "for batchidx in range(num_datasets):\n",
    "    random_errors[batchidx] = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n4),cov=np.diag(np.ones(n4)),random_state=2001+batchidx),(n4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 15, 1) (25, 15, 9)\n"
     ]
    }
   ],
   "source": [
    "# Define true parameter beta = [0.8,1.5,0,...,0]\n",
    "trueBeta = np.reshape(np.concatenate(([0.8,1.5],np.zeros(p4-2)),axis=0),(-1,1))\n",
    "response = np.matmul(datasets,trueBeta) + random_errors\n",
    "print(response.shape, datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now need to save the datasets and responses in a numpy file\n",
    "filename = \"Data/GeneratedSets25x15x9.pickle\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([datasets,response],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dependent Case with Multicollinearity'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Dependent Case with Multicollinearity\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a design matrix X with n = 70 iid examples and p = 6 predictors distribution\n",
    "# Suppose the first 2 predictors are independent, X3 = 4X1-2X2, X4 independent of X1,X2,X3 , X5 = 3X3 -6X4, X6 independent\n",
    "n5 = 70\n",
    "p5 = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeromean = np.zeros(4)\n",
    "covI = np.diag(np.ones(4))\n",
    "\n",
    "# Use seed 44 to generate X_1,X_2,X_4,X_6\n",
    "X1246 = stats.multivariate_normal.rvs(mean=zeromean,cov=covI,size=n5,random_state=44)\n",
    "X3 = np.reshape(4*X1246[:,0]-2*X1246[:,1],(-1,1))+np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n5),cov=np.diag(np.ones(n5)),random_state=1),(-1,1))\n",
    "X5 = 3*X3 - np.reshape(6*X1246[:,2],(-1,1)) + np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n5),cov=np.diag(np.ones(n5)),random_state=2),(-1,1))\n",
    "X = np.concatenate((np.reshape(X1246[:,:2],(n5,2)),X3,np.reshape(X1246[:,2],(-1,1)),X5,np.reshape(X1246[:,3],(-1,1))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate the response y.\n",
    "# Assume y = XB with true Beta = [0.8,-1.5,0.1,0,...,0]\n",
    "# Use seed 102 to generate the regression errors\n",
    "\n",
    "true_beta = np.reshape(np.concatenate(([0.8,-1.5,0.1],np.zeros(p5-3))),(-1,1))\n",
    "random_errors = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n5),cov=np.diag(np.ones(n5)),random_state=102), (-1,1))\n",
    "y = np.matmul(X,true_beta) + random_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to save X and y\n",
    "filename = \"Data/training_data_Correlated70x6.pickle\" # Aim to save the data in this file\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename)) # Create the Data Directory...\n",
    "except FileExistsError:\n",
    "    pass # Unless it already exists, in which case, do nothing\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([X,y],file) # Dump the training data into the aforementioned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 6) (70, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 different datasets X with 70 examples and p=6 parameters\n",
    "# X3 = 4X1-2X2 + eps, X5 = 3X3 -6X4 + eps, X6 independent\n",
    "# Use random seeds 201,202,...,225 to generate X1,X2,X4,X6 from MVN(0,I) 70x4 matrix\n",
    "n6 = 70\n",
    "p6 = 6\n",
    "num_datasets = 50\n",
    "\n",
    "datasets = np.zeros((num_datasets,n6,p6))\n",
    "for batchidx in range(num_datasets):\n",
    "    X1246 = stats.multivariate_normal.rvs(mean=np.zeros(4),cov=np.diag(np.ones(4)),random_state=201+batchidx,size=n6)\n",
    "    X3 = np.reshape(4*X1246[:,0]-2*X1246[:,1],(-1,1))+np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n6),cov=np.diag(np.ones(n6)),random_state=1+batchidx),(-1,1))\n",
    "    X5 = 3*X3 - np.reshape(6*X1246[:,2],(-1,1)) + np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n6),cov=np.diag(np.ones(n6)),random_state=2+batchidx),(-1,1))\n",
    "    X = np.concatenate((np.reshape(X1246[:,:2],(n6,2)),X3,np.reshape(X1246[:,2],(-1,1)),X5,np.reshape(X1246[:,3],(-1,1))),axis=1)\n",
    "    datasets[batchidx] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset, generate random errors from a MVN(0,1) distribution of dimension n6\n",
    "# Use random seeds 3001,...,3025\n",
    "random_errors = np.zeros((num_datasets,n6,1))\n",
    "for batchidx in range(num_datasets):\n",
    "    random_errors[batchidx] = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n6),cov=np.diag(np.ones(n6)),random_state=3001+batchidx),(n6,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 70, 1) (50, 70, 6)\n"
     ]
    }
   ],
   "source": [
    "# Define true parameter beta = [0.8,-1.5,0.1,0,...,0]\n",
    "trueBeta = np.reshape(np.concatenate(([0.8,-1.5,0.1],np.zeros(p6-3)),axis=0),(-1,1))\n",
    "response = np.matmul(datasets,trueBeta) + random_errors\n",
    "print(response.shape, datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now need to save the datasets and responses in a numpy file\n",
    "filename = \"Data/CorrelatedSets50x70x6.pickle\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([datasets,response],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n7 = 13\n",
    "p7 = 16\n",
    "# Try for 14 true non zero beta components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeromean = np.zeros(p7)\n",
    "covI = np.diag(np.ones(p7))\n",
    "\n",
    "# Use seed 42 to generate X\n",
    "X = stats.multivariate_normal.rvs(mean=zeromean,cov=covI,size=n7,random_state=45)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate the response y.\n",
    "# Assume y = XB with true Beta generated from MVN(10,4Ip)\n",
    "# Use seed 100 to generate the regression errors\n",
    "\n",
    "nonzerobeta = stats.multivariate_normal.rvs(10*np.ones(14),9*np.diag(np.ones(14)),random_state=100000)\n",
    "nonzerobeta\n",
    "true_beta = np.reshape(np.concatenate((nonzerobeta,np.zeros(2))),(-1,1))\n",
    "random_errors = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n7),cov=np.diag(np.ones(n7)),random_state=100), (-1,1))\n",
    "y = np.matmul(X,true_beta) + random_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to save X and y\n",
    "filename = \"Data/training_data13x16.pickle\" # Aim to save the data in this file\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename)) # Create the Data Directory...\n",
    "except FileExistsError:\n",
    "    pass # Unless it already exists, in which case, do nothing\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([X,y],file) # Dump the training data into the aforementioned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13, 16), (13, 1))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 different datasets X with 13 samples from a MVN(0,I) dataset with p=16 parameters\n",
    "n8 = 13\n",
    "p8 = 16\n",
    "num_datasets = 50\n",
    "\n",
    "datasets = np.zeros((num_datasets,n8,p8))\n",
    "for batchidx in range(num_datasets):\n",
    "    datasets[batchidx] = stats.multivariate_normal.rvs(mean=np.zeros(p8),cov=np.diag(np.ones(p8)),random_state = batchidx+301,size=n8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random seeds 1001,...,1050\n",
    "random_errors = np.zeros((num_datasets,n8,1))\n",
    "for batchidx in range(num_datasets):\n",
    "    random_errors[batchidx] = np.reshape(stats.multivariate_normal.rvs(mean=np.zeros(n8),cov=np.diag(np.ones(n8)),random_state=4001+batchidx),(n8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.88528887],\n",
       "       [ 8.97889158],\n",
       "       [10.63234983],\n",
       "       [10.14569967],\n",
       "       [12.87414851],\n",
       "       [ 8.0020032 ],\n",
       "       [ 9.90012985],\n",
       "       [13.13669927],\n",
       "       [12.28933273],\n",
       "       [11.5908425 ],\n",
       "       [11.2033932 ],\n",
       "       [ 7.08207155],\n",
       "       [ 5.86457569],\n",
       "       [14.50343311],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzerobeta = stats.multivariate_normal.rvs(10*np.ones(14),9*np.diag(np.ones(14)),random_state=100001)\n",
    "true_beta = np.reshape(np.concatenate((nonzerobeta,np.zeros(2))),(-1,1))\n",
    "true_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 13, 1) (50, 13, 16)\n"
     ]
    }
   ],
   "source": [
    "response = np.matmul(datasets,true_beta) + random_errors\n",
    "print(response.shape, datasets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now need to save the datasets and responses in a numpy file\n",
    "filename = \"Data/GeneratedSets50x13x16.pickle\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(filename))\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "with open(filename,\"wb\") as file:\n",
    "    pickle.dump([datasets,response],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
